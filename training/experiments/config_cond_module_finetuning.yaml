debug: True
EXPEc_DATA:    null 
save_path:      null
wandb_log: False 
project_name: null
log_freq: 1
val_freq: 1
print_freq: 1
save_freq: 1
cosine_annealing: False
save_optim:     True
resume:         False
resume_path:    null
resume_step:    -1
device:         0
exp_name:       -1
epochs:         10
bsize:          32
vsize:          ${bsize} # optionally, set to a different batchsize for validation loader
optimizer:      null #Adam # RMSProp
loss: ""
bb_sequence: 1
action_sequence: 1
task_names: null
rollout: False
dataset_target: 'multi_task_il.datasets.command_encoder.command_encoder_dataset.CommandEncoderFinetuningDataset'
# loss multipliers
# inv_mul:        0
# bc_mul:         0
# ce_mul:        0
# pnt_mul:        0
# rep_muls:
#   img_byol:           ${byol.mul_pre}
#   attn_byol:          ${byol.mul_pos}
#   demo_byol:          ${byol.mul_demo}
#   intm_byol:          ${byol.mul_intm}
#   simclr_pre:         ${simclr.mul_pre}
#   simclr_post:        ${simclr.mul_pos}
#   simclr_intm:        ${simclr.mul_intm}

train_cfg:
  batch_size:           ${bsize}
  val_size:             ${vsize}
  lr:                   1e-4
  optimizer:            ${optimizer}
  epochs:               ${epochs}
  log_freq:             ${log_freq}
  save_freq:            ${save_freq}
  print_freq:           ${print_freq}
  val_freq:             ${val_freq}
  inv_loss_mult:        ${inv_mul}
  bc_loss_mult:         ${bc_mul}
  pnt_loss_mult:        ${pnt_mul}
  rep_loss_muls:        ${rep_muls}
  dataset:              ${dataset_cfg}
  sampler:              ${samplers}
  target_update_freq:   5  # used for soft parameter update
  early_stopping: ${early_stopping_cfg}
  weight_decay:  0.00 #0.05
  lr_schedule: null #'ExponentialDecay' #'ReduceLROnPlateau'
  # rate_exponential_decay: 0.1

# early stopping configurator
early_stopping_cfg:
  patience: 10
  delta: 1e-3

# tasks related
tasks:       ???
single_task: False 
exclude_task: False 
use_all_tasks: False 
set_same_n:   -1 
limit_num_traj: -1
limit_num_demo: -1
defaults:
  - tasks_cfgs:  7_tasks

# dataset/loader/samplers
loader_workers:   20
samplers:        
  batch_size:         ${bsize}
  drop_last:          False
  shuffle:            True 
  # Policy 1: At each slot is assigned a RandomSampler
  balancing_policy: 0 # 0, 1, 2 
val_skip:             True # whether to let the samplers skip some **sub**tasks
train_skip:           True


sampler_cfg:
  # _target_: ${sampler_target}
  shuffle: True
      
dataset_cfg:
  _target_: ${dataset_target}
  mode: 'train'
  jsons_folder: '/raid/home/frosa_Loc/Multi-Task-LFD-Framework/repo/Multi-Task-LFD-Training-Framework/bashes'
  demo_T: 4
  width: 180
  height: 100
  aug_twice: True
  aux_pose: True
  use_strong_augs: target_update_freq
  data_augs: ${augs}
  black_list: ['taco_play_converted', 'droid_converted']
  demo_crop: [0,0,0,0]
  select_random_frames: False

augs:
  old_aug: false
  brightness: [0.9, 1.1]
  contrast: [0.9, 1.1]
  saturation: [0.9, 1.1]
  hue: [0.0, 0.0]
  p: 0.1 
  horizontal_flip_p: 0.1
  brightness_strong: [0.875, 1.125]
  contrast_strong: [0.5, 1.5]
  saturation_strong: [0.5, 1.5]
  hue_strong: [-0.05, 0.05]
  p_strong: 0.5 
  horizontal_flip_p_strong: 0.5
  null_bb: True

# model related
policy: ???  # set to any set of configs via command line, e.g. policy='${tosil}'

##### TODO
# 1째 addestramento:
#   A) dim: panda sim  -- ur5 sim -> Tasso medio di successo (correlazione tra tasso medio e MSE)
#   B) test su istanze mai viste
# 2째 addestramento:
#   A) dim: panda sim -- ur5 reale FROM SCRATCH
# 3째 addestramento:
#   A) dim: panda sim -- ur5 reale FINETUNING dal checkpoint punto 1째

#--- Policy ---
# shape: [3, ${dataset_cfg.height}, ${dataset_cfg.width}]


cond_module:
  _target_: multi_task_il.datasets.command_encoder.cond_module.CondModule
  height: 120
  width: 160
  demo_T: 4
  model_name: 'r2plus1d_18'
  pretrained: True
  cond_video: True
  n_layers: 3
  demo_W: 7
  demo_H: 7
  demo_ff_dim: [128, 64, 32]
  demo_linear_dim: [512, 512, 512]
  conv_drop_dim: 3