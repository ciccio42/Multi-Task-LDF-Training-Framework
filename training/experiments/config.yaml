debug: True
EXPERT_DATA:    null 
save_path:      null
wandb_log: True 
project_name: null
log_freq: 1
val_freq: 1
print_freq: 1
save_freq: 1
cosine_annealing: False
save_optim:     True
resume:         False
resume_path:    null
resume_step:    -1
device:         0
exp_name:       -1
epochs:         10
bsize:          30
vsize:          ${bsize} # optionally, set to a different batchsize for validation loader
optimizer:      null #Adam # RMSProp
loss: ""
bb_sequence: 1
action_sequence: 1
task_names: null
rollout: False
dataset_target: 'multi_task_il.datasets.multi_task_datasets.MultiTaskPairedDataset'
# loss multipliers
inv_mul:        0
bc_mul:         0
ce_mul:        0
pnt_mul:        0
rep_muls:
  img_byol:           ${byol.mul_pre}
  attn_byol:          ${byol.mul_pos}
  demo_byol:          ${byol.mul_demo}
  intm_byol:          ${byol.mul_intm}
  simclr_pre:         ${simclr.mul_pre}
  simclr_post:        ${simclr.mul_pos}
  simclr_intm:        ${simclr.mul_intm}

train_cfg:
  batch_size:           ${bsize}
  val_size:             ${vsize}
  lr:                   1e-3 #5e-4
  optimizer:            ${optimizer}
  epochs:               ${epochs}
  log_freq:             ${log_freq}
  save_freq:            ${save_freq}
  print_freq:           ${print_freq}
  val_freq:             ${val_freq}
  inv_loss_mult:        ${inv_mul}
  bc_loss_mult:         ${bc_mul}
  pnt_loss_mult:        ${pnt_mul}
  rep_loss_muls:        ${rep_muls}
  dataset:              ${dataset_cfg}
  sampler:              ${samplers}
  target_update_freq:   5  # used for soft parameter update
  early_stopping: ${early_stopping_cfg}
  weight_decay:  0.05
  lr_schedule: 'ReduceLROnPlateau' # ExponentialDecay

# early stopping configurator
early_stopping_cfg:
  patience: -1
  delta: 1e-3

# tasks related
tasks:       ???
single_task: False 
exclude_task: False 
use_all_tasks: False 
set_same_n:   -1 
limit_num_traj: -1
limit_num_demo: -1
defaults:
  - tasks_cfgs:  7_tasks

# dataset/loader/samplers
loader_workers:   20
samplers:        
  batch_size:         ${bsize}
  drop_last:          False
  shuffle:            True 
  # Policy 1: At each slot is assigned a RandomSampler
  balancing_policy: 0 # 0, 1, 2 
val_skip:             True # whether to let the samplers skip some **sub**tasks
train_skip:           True

dataset_cfg:
  _target_:         ${dataset_target}
  root_dir:         ${EXPERT_DATA}
  mode:             ???
  tasks_spec:       ${tasks}
  aux_pose:         True # only required for DAML baseline 
  height:           100 # 224 # 200 # 100
  width:            180 # 224 # 360 # 180
  split:            [0.90, 0.10]
  demo_T:           4
  obs_T:            7
  bbs_T: ${bb_sequence}
  action_T: ${action_sequence}
  normalize_action: True
  load_bb: True
  # x, y, z, e_x, e_y, e_z
  normalization_ranges: [[-0.35,  0.35],
                        [-0.35,  0.35],
                        [ 0.60,  1.20],
                        [-3.14,  3.14911766],
                        [-3.14911766, 3.14911766],
                        [-3.14911766,  3.14911766]]
  # use when convert is true
  # normalization_ranges: [[-0.40,  0.40],
  #                       [0.10,  0.90],
  #                       [ -0.20,  0.20],
  #                       [-3.14911766,  3.14911766],
  #                       [-3.14911766, 3.14911766],
  #                       [-3.14911766,  3.14911766]]
  n_action_bin: 256
  take_first_frame: ${policy.concat_target_obj_embedding}
  data_augs:        ${augs}
  non_sequential:   False
  crop_twice:       True
  state_spec:       [joint_pos, gripper_state]
  allow_val_skip:   ${val_skip}
  allow_train_skip: ${train_skip}
  use_strong_augs:  True 
  select_random_frames: True
  compute_obj_distribution: False
  agent_name: 'ur5e'
  demo_name: 'panda'
  perform_augs: True
  change_command_epoch: True
  load_eef_point: False
  split_pick_place: False
  convert_action: False

augs:
  # strong_jitter:     1  
  # weak_jitter:       1 # 0.1 Mosaic; 1 Tosil 
  # grayscale:         1 # 0.1 Mosaic; 1 Tosil
  # blur:              [0.1, 2.0] 
  # flip:              0.05   # only flip for the strong augs
  # weak_crop_scale:   [0.8, 1.0]  # [0.8, 1.0] Mosaic; [0.99, 1.0] Tosil
  # strong_crop_scale: [0.8, 1.0] # [0.8, 1.0] Mosaic; [0.99, 1.0] Tosil
  # weak_crop_ratio:   [1.8, 1.8] # [1.8, 1.8] Mosaic; [1.0, 1.0] Tosil
  # strong_crop_ratio: [1.8, 1.8] # [1.8, 1.8] Mosaic; [1.0, 1.0] Tosil
  # use_affine:        False  
  # rand_trans:        0.1

  old_aug: false
  brightness: [0.9, 1.1]
  contrast: [0.9, 1.1]
  saturation: [0.9, 1.1]
  hue: [0.0, 0.0]
  p: 0.1 
  horizontal_flip_p: 0.1
  
  brightness_strong: [0.875, 1.125]
  contrast_strong: [0.5, 1.5]
  saturation_strong: [0.5, 1.5]
  hue_strong: [-0.05, 0.05]
  p_strong: 0.5 
  horizontal_flip_p_strong: 0.5

  null_bb: True
# model related
policy: ???  # set to any set of configs via command line, e.g. policy='${tosil}'

simclr:
  demo_T:           ${train_cfg.dataset.demo_T}
  obs_T:            ${train_cfg.dataset.obs_T} 
  mul_pre:          1
  mul_pos:          1
  mul_intm:         0
  tau:              0.005      
  compressor_dim:   128
  temporal:         True
  hidden_dim:       512 #256
  fix_step:         -1 

byol: 
  p:                2
  project_dim:      128
  hidden_dim:       256
  demo_T:           ${train_cfg.dataset.demo_T}
  obs_T:            ${train_cfg.dataset.obs_T}   
  demo_proj:        True
  share_mlp:        True 
  no_hidden:        False
  draw_apart:       False
  mul_pre:          0
  mul_pos:          0
  mul_intm:         0 
  mul_demo:         0

actions:
  n_layers:         2    
  out_dim:          64
  hidden_dim:       128
  adim:             8
  n_mixtures:       2   
  const_var:        False
  sep_var:          True 
  concat_demo_head:   False
  concat_demo_act:    True
  concat_img_emb: True
  concat_demo_emb: True
  demo_mean:        ${policy.demo_mean}
  is_recurrent: False
  lstm_config: ${lstm}

attn:
  embed_hidden:     256
  dropout:          0.2
  n_attn_layers:    2
  attn_heads:       4
  attn_ff:          128
  pos_enc:          True 
  fuse_starts:      0   # default 0 so attend everywhere
  causal:           True
  attend_demo:      True
  demo_out:         True
  max_len:          5000    
  img_cfg:           
    network_flag:   0 # e.g Res18  
    out_feature:    256
    drop_dim:       3
    pretrained:     False 


##### TODO
# 1째 addestramento:
#   A) dim: panda sim  -- ur5 sim -> Tasso medio di successo (correlazione tra tasso medio e MSE)
#   B) test su istanze mai viste
# 2째 addestramento:
#   A) dim: panda sim -- ur5 reale FROM SCRATCH
# 3째 addestramento:
#   A) dim: panda sim -- ur5 reale FINETUNING dal checkpoint punto 1째

#--- Policy ---
# shape: [3, ${dataset_cfg.height}, ${dataset_cfg.width}]


#TODO: inserire configurazione per istanziare RT1_video_cond
# rt1_conditioner:
#   _target_:

cond_module_path: null

rt1_video_cond:
  _target_: multi_task_il.models.rt1.repo.pytorch_robotics_transformer.rt1_video_cond.RT1_video_cond
  ### rt1 params
  input_tensor_space:
    image:
      low: 0.0
      high: 1.0
      shape:
        - 3
        - ${dataset_cfg.height}
        - ${dataset_cfg.width}
      dtype: numpy.float32
    natural_language_embedding:
      low: float("-inf")  # -1.0
      high: float("inf")  # 1.0
      shape: [512]
      dtype: numpy.float32
  output_tensor_space:
    # terminate_episode: 2 #TODO: valutare se metterlo
    world_vector:
      low: -1.0
      high: 1.0
      shape: [3]
      dtype: numpy.float32
    # rotation_delta:
    #   low: -numpy.pi/2
    #   high: numpy.pi/2
    #   shape: [3]
    #   dtype: numpy.float32
    rotation_delta:
      low: -1.0
      high: 1.0
      shape: [3]
      dtype: numpy.float32
    gripper_closedness_action:
      low: -1.0
      high: 1.0
      shape: [1]
      dtype: numpy.float32
  train_step_counter: 0
  vocab_size: 256
  token_embedding_size: 512
  num_layers: 1
  layer_size: 4096
  num_heads: 8
  feed_forward_size: 512
  dropout_rate: 0.1
  time_sequence_length: 6 # 7
  crop_size: 236
  use_token_learner: True
  return_attention_scores: False
  img_height: ${dataset_cfg.height}
  img_width: ${dataset_cfg.width}
  # action_order: Optional[List[str]] = None
  concat_target_obj_embedding: False
  ### cond_module paramams
  height: 120 # not used
  width: 160 # not used
  demo_T: 4
  model_name: "r2plus1d_18"
  pretrained: True
  cond_video: True
  n_layers: 3
  demo_W: 7
  demo_H: 7
  demo_ff_dim: [128, 64, 32]
  demo_linear_dim: [512, 512, 512]
  conv_drop_dim: 3
  cond_module_model_path: ${cond_module_path}
  #'/user/frosa/multi_task_lfd/checkpoint_save_folder/1Task-pick_place-cond_module_no_lr_1e-4-Batch32/model_save-24.pt'
  # cond_module_model_path: '/user/frosa/multi_task_lfd/checkpoint_save_folder/1Task-pick_place-cond_module_v2-Batch32/model_save-24.pt'
  # cond_module_model_path: '/user/frosa/multi_task_lfd/checkpoint_save_folder/1Task-pick_place-cond_module-Batch32/model_save-72.pt'
  # cond_module_model_path: '/user/frosa/multi_task_lfd/checkpoint_save_folder/1Task-pick_place-cond_module-Batch32/model_save-72.pt'
  # cond_module_model_path: '/user/frosa/multi_task_lfd/checkpoint_save_folder/1Task-pick_place-cond_module_v2-Batch32/model_save-120.pt'
  # cond_module_model_path: '/raid/home/frosa_Loc/Multi-Task-LFD-Framework/repo/Multi-Task-LFD-Training-Framework/training/train_scripts/command_encoder/models/panda/32_batch_size/5_epochs/0.0001_lr/cond_module_12-03_12:29.pth'
  # cond_module_model_path: '/raid/home/frosa_Loc/Multi-Task-LFD-Framework/repo/Multi-Task-LFD-Training-Framework/training/train_scripts/command_encoder/models/batch_size/32_batch_size/num_epochs/4_epochs/0.0001_lr/cond_module_11-05_00:03.pth'

rt1:
  _target_: multi_task_il.models.rt1.repo.pytorch_robotics_transformer.transformer_network.TransformerNetwork
  input_tensor_space:
    image:
      low: 0.0
      high: 1.0
      shape:
        - 3
        - ${dataset_cfg.height}
        - ${dataset_cfg.width}
      dtype: numpy.float32
    natural_language_embedding:
      low: float("-inf")
      high: float("inf")
      shape: [512]
      dtype: numpy.float32
  output_tensor_space:
    terminate_episode: 2
    world_vector:
      low: -1.0
      high: 1.0
      shape: [3]
      dtype: numpy.float32
    rotation_delta:
      low: -numpy.pi/2
      high: numpy.pi/2
      shape: [3]
      dtype: numpy.float32
    gripper_closedness_action:
      low: -1.0
      high: 1.0
      shape: [1]
      dtype: numpy.float32
  train_step_counter: 0
  vocab_size: 256
  token_embedding_size: 512
  num_layers: 1
  layer_size: 4096
  num_heads: 8
  feed_forward_size: 512
  dropout_rate: 0.1
  time_sequence_length: 1
  crop_size: 236
  use_token_learner: True
  return_attention_scores: False
  img_height: ${dataset_cfg.height}
  img_width: ${dataset_cfg.width}
  # action_order: Optional[List[str]] = None,
  concat_target_obj_embedding: False

mosaic:
  _target_:           multi_task_il.models.mt_rep.VideoImitation 
  load_target_obj_detector: False
  target_obj_detector_step: 0
  target_obj_detector_path: null
  freeze_target_obj_detector: False
  remove_class_layers: False
  load_contrastive: True
  load_inv: True
  concat_target_obj_embedding: False
  latent_dim:         40
  sdim:               7
  concat_state:       True
  concat_bb:       True
  zero_bb_after_pick: False
  bb_sequence:     ${bb_sequence}
  height:             ${train_cfg.dataset.height}
  width:              ${train_cfg.dataset.width} 
  demo_T:             ${train_cfg.dataset.demo_T}
  obs_T:              ${train_cfg.dataset.obs_T}   
  dim_H:              7
  dim_W:              12  
  demo_mean:          True 
  action_cfg:         ${actions}
  concat_demo_head:   False
  concat_demo_act:    True 
  attn_cfg:           ${attn}
  byol_config:        ${byol}
  simclr_config:      ${simclr}

tosil:
  _target_:         multi_task_il.models.baselines.InverseImitation 
  concat_target_obj_embedding: False
  latent_dim:       40
  lstm_config:
    out_dim:        32
    n_layers:       1
    is_rnn:         False
  vis:
    conv_drop_dim:  3 
    st_goal_attn:   True
    n_st_attn:      2
    use_pe:         True
    attn_heads:     4
  adim: 7
  n_mixtures:       2
  const_var:        True
  concat_state:     False
  pred_point:       True

lstm:
  hidden_dim: 64
  n_layers:       1
  forward_t: ${action_sequence}
  